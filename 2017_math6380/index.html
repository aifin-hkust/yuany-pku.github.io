<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
   <META http-equiv=Content-Type content="text/html; charset=gb2312">
   <title>Math6380J: Mathematical Introduction to Data Analysis </title>
</head>
<body background="../images/crysback.jpg">

<!-- PAGE HEADER -->

<div class="Section1">
<table border="0" cellpadding="0" width="100%" style="width: 100%;">
      <tbody>
        <tr>

       <td style="padding: 0.75pt;" width="80" align="center">

      <p class="MsoNormal">&nbsp;<img width="64"
 id="_x0000_i1025"
 src="../images/HKUST_logo.jpg" alt="PKU">
          </p>
       </td>
       <td style="padding: 0.75pt;">
      <p>
<span style="font-size: 18pt;">
<b><big>Math 6380J: A Mathematical Introduction to Data Analysis<br>
   Spring 2017</big></b>
<br>
</p>
</td>
</tr>

</tbody>
</table>

<div class="MsoNormal" align="center" style="text-align: center;">
<hr size="2" width="100%" align="center">  </div>

<ul type="disc">

</ul>

<!-- COURSE INFORMATION BANNER -->

<table border="0" cellpadding="0" width="100%" bgcolor="#990000"
 style="background: rgb(153,0,0) none repeat scroll 0% 50%; width: 100%;">
      <tbody>

        <tr>
       <td style="padding: 2.25pt;">
      <p class="MsoNormal"><b><span
 style="font-size: 13.5pt; color: white;">Course Information</span></b></p>
       </td>
      </tr>

  </tbody>
</table>

<!-- COURSE INFORMATION -->

<!-- 
    <p style="margin-left: 0.5in;">
    <img height="200" src="boya_starry.png">
    <img height="200" src="boya_wreck.png">
    <img height="200" src="boya_twilight.png">
    </p>
-->

<h3>Synopsis (&#25688;&#35201;)</h3>
<p style="margin-left: 0.5in;">
<big> This course is open to graduates and senior undergraduates in applied mathematics and statistics who are interested in learning from data.
Students with other backgrounds such as engineering and biology are also welcome, provided you have certain maturity of mathematics. 
It starts from two curses of dimensionality: Stein's Phenonema and random matrix theory in PCA, then covers some fundamental topics on 
high dimensional statistics, manifold learning, diffusion geometry, random walks on graphs, concentration of measure, 
random matrix theory, geometric and topological methods, etc. 
<br>
Prerequisite: linear algebra, basic probability and multivariate statistics, basic stochastic process (Markov chains), convex optimization; familiarity with Matlab, R, and/or Python, etc.
</big>
</p>


<h3>Reference (&#21442;&#32771;&#25945;&#26448;)</h3>
<p style="margin-left: 0.5in;">
 <big> <a href="https://yao-lab.github.io/book_datasci/"> [pdf download] </a> <img src="../images/new.jpg" height="40">
 </big>
 </p>

<p style="margin-left: 0.5in;">
<big>
<em> <a href="https://web.stanford.edu/~hastie/CASI/">Computer Age Statistical Inference: Algorithms, Evidence, and Data Science.</a> By Efron and Hastie. A new monograph on computational statistics and 'learning'. </em>
</big>
</p>

<p style="margin-left: 0.5in;">
<big>
<em> <a href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/">The Elements of Statistical Learning.</a> 2nd Ed. By Hastie, Tibshirani, and Friedman. A classic textbook on statistical learning for graduate students with interests on statistical thinking of machine learning. </em>
</big>
</p>

<p style="margin-left: 0.5in;">
<big>
<em> <a href="http://www-bcf.usc.edu/~gareth/ISL/">An Introduction to Statistical Learning, with applications in R.</a> By James, Witten, Hastie, and Tibshirani. A simplified version of the textbook above for undergraduates, with extensive lab sessions on R programming. </em>
</big>
</p>

<h3>Instructors: </h3>
<p style="margin-left: 0.5in;">
<big>
<em><a href="http://yao-lab.github.io/">Yuan YAO</a>  </em>
</big>
</p>

<h3>Time and Place:</h3>
<p style="margin-left: 0.5in;">
<big><em>Monday 6:30pm-9:20pm, Rm 5510 (Lift 25-26) </em> <br> </big>
This term we will be using Piazza for class discussion. The system is highly catered to getting you help fast and efficiently from classmates and myself. Rather than emailing questions to the teaching staff, I encourage you to post your questions on Piazza. If you have any problems or feedback for the developers, email team@piazza.com. <br>
<big><em>Find our class page at: <a href="https://piazza.com/ust.hk/spring2017/math6380/home">https://piazza.com/ust.hk/spring2017/math6380/home</a></em></big> <br>
</p>

<h3>Homework and Projects:</h3>

<p style="margin-left: 0.5in;">
<big><em>Monthly mini-projects and a final major project. No final exam. </em>
</big></p>

<p style="margin-left: 0.5in;">
 <big> <a href="https://github.com/yuany-pku/2017_math6380"> [Project Reports] </a> <img src="http://math.stanford.edu/~yuany/images/new.jpg" height="40">
 </big>
 </p>


<!-- <h3>Teaching Assistant (&#21161;&#25945;):</h3>
    <p style="margin-left: 0.5in;">
    <big>SUN, Xinwei; XIONG, Jiechao; YUAN, Huizhuo; WU, Bingzhe. <br>
    Email:<em> statlearning_hw (add "@ 126 DOT com" afterwards) </em>
    </big>
    </p>
-->
				
<h3>Schedule (&#26102;&#38388;&#34920;)</h3>

<table border="1" cellspacing="0">
<tbody>

<tr>
<td align="left"><strong>Date</strong></td>
<td align="left"><strong>Topic</strong></td>
<td align="left"><strong>Instructor</strong></td>
<td align="left"><strong>Scriber</strong></td>
</tr>

<tr>
<td>02/06/2017, Mon </td>
<td>Lecture 01: Introduction, Geometry of PCA (Chap 1 Sec 1), MLE (Chap 2 Sec 1)<br>
<ul>[Reference]:
<li> To view .jpynb files below, you may try <a href="https://nbviewer.jupyter.org/"> [ Jupyter NBViewer] </a> </li> 
<li> PCA in iPython Notebook <a href="pca.ipynb"> [ pca.ipynb ] </a> <a href="pca.py"> [ pca.py ] </a> </li>
<li> PCA with Logistic regression for digit classification: <a href="pca_logistic.ipynb"> [ pca_logistic.ipynb ] </a> <a href="pca_logistic.py"> [ pca_logistic.py ] </a> </li>
<!-- <li> <a href="http://pan.baidu.com/s/1kTw7Ogv"> [ slides in pdf ] </a> </li> -->
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>02/13/2017, Mon </td>
<td>Lecture 02: Stein's Estimate of Mean and Parallel Analysis for PCA (Chap 2 Sec 2, Efron-Hastie Chap 7.)<br>
<ul>[Reference]: the following codes are made in R language, please let me know had you found good sources in other languages
<li> Stein's Estimate vs. MLE <a href="james_stein.R"> [ james_stein.R ] </a> </li>
<li> Horn's Parallel Analysis for PCA <a href="paran.R"> [ paran.R ] </a> with S&P500 data in class: <a href="snp500.Rda"> [ snp500.Rda ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>02/20/2017, Mon </td>
<td>Lecture 03: MLE, Linear, JS, LASSO, Hard Thresholding, Nonconvex Regularization, LBI(ISS): Risk and Consistency <a href="lecture03.pdf">[Lecture Note]</a><br>
<ul>[Reference]: 
<li> R package "Libra": Linearized Bregman Algorithm <a href="https://cran.r-project.org/web/packages/Libra/index.html"> [ Cran R ] </a> </li>
<li> Tutorial on "Libra": <a href="https://arxiv.org/abs/1604.05910"> [ arXiv ] </a> <a href="http://math.stanford.edu/~yuany/course/reference/BigData_004_final_v8.pdf"> [ English ]</a> <a href="http://math.stanford.edu/~yuany/course/reference/Libra_Tutorial_springer.pdf"> [Chinese] </a> </li>
<li> Some R codes: <a href="lbi.R"> [ lbi.R ] </a> <a href="diabetes.R"> [ diabetes.R ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td>Jiacheng XIA</td>
</tr>

<tr>
<td>02/27/2017, Mon </td>
<td>Lecture 04: Mini-Project 1 and some pick-up on Random Matrix Theory for PCA <a href="Lecture04.pptx"> [ Lecture04.pptx ]</a><br>
<ul>[Reference]: 
<li> Matlab simulation on Marcenko-Pastur distribution <a href="mp.m"> [ mp.m ] </a> </li>
<li> <a href="https://arxiv.org/abs/math/0611589">[Johnstone06]</a> Johnstone, I (2006) High Dimensional Statistical Inference and Random Matrices. arXiv:0611589. </li>
<li> <a href="http://www.cmapx.polytechnique.fr/~benaych/sam10_v2.pdf">[Nadakuditi10]</a> Nadakuditi, R. R. and F. Benaych-Georges (2010) The breakdown point of signal subspace estimation. IEEE Sensor Array and Multichannel Signal Processing Workshop (October 2010), pg. 177-180.</li>
<li> Description of mini-project 1 <a href="project1.pdf"> [ project1.pdf ] </a> </li>
<li> <a href="http://piazza.com/ust.hk/spring2017/math6380"> Piazza Q&A room </a> </li>
<li> <a href="https://inclass.kaggle.com/c/drugsensitivity/"> [ Kaggle inclass contest on Cleave Drug Sensitivity Prediction ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>03/06/2017, Mon </td>
<td>Lecture 05: SDP relaxations, RPCA, and SPCA (Chap 4: 1-4)<br>
<ul>[Seminar]: 
<li> Speaker: Bowei YAN, U Texas-Austin </li>
<li> Title: Semidefinite relaxations for clustering <a href="http://math.stanford.edu/~yuany/course/reference/YAN_Bowei.pdf"> [ slides ]</a> </li>
<li> Abstract: In recent years, a number of works have studied methods for community detection in stochastic block models (SBM) via semidefinite relaxations. Among various proposed Semidefinite Programming approaches, there are usually conditions required on the sparsity of the graph, the separation of the clusters, and the number and the size of the clusters. 

In this talk I will introduce an SDP that uses the projection matrix instead of the indicator clustering matrix. We prove that this formulation recovers the ground truth structure with weaker conditions on each of the aforementioned aspects. The proposed relaxation can also be used for kernel clustering and is shown to be robust with respect to arbitrary outliers compared to existing spectral based methods.

This is a joint work with Purnamrita Sarkar.
</li>
</ul>
<ul>[Reference]: 
<li> You need Matlab <a href="http://cvxr.com/cvx/">CVX</a> optimization toolbox to run the following demo codes.
<li> Robust PCA demo: <a href="http://math.stanford.edu/~yuany/course/data/testRPCA.m"> [ testRPCA.m ] </a> </li>
<li> Sparse PCA demo: <a href="http://math.stanford.edu/~yuany/course/data/testSPCA.m"> [ testSPCA.m ] </a> </li>
<li> Yi MA's website on large scale Robust PCA algorithms <a href="http://perception.csl.illinois.edu/matrix-rank/home.html"> [ Yi MA's UIUC web ] </a> </li>
<li> Bowei's Matlab codes for SDP-based clustering via ADMM <a href="https://boweiyan.github.io/files/sbm_cov_code.zip"> [ sbm_cov_code.zip ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>03/13/2017, Mon </td>
<td>Lecture 06: Supervised PCA, Dual PCA-MDS, and Reproducing Kernel <a href="lecture06.pdf"> [ lecture06.pdf ]</a><br>
<ul>[Reference]: 
<li> Python MDS in scikit-learn: <a href="http://scikit-learn.org/stable/auto_examples/manifold/plot_mds.html"> [ plot_mds.html ] </a> </li>
<li> Localized Sliced Inverse Regression in Matlab: <a href="http://www2.stat.duke.edu/~km68/lsir.htm"> [ lsir at Duke ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td>Yuqi ZHAO</td>
</tr>

<tr>
<td>03/20/2017, Mon </td>
<td>Lecture 07: RKHS, SVM, and MDS with incomplete information (<a href="lecture06.pdf"> Last part of lecture06.pdf </a> and Chap 4.5-4.6) <br>
<ul>[Reference]: 
<li> Python SVM in scikit-learn: <a href="http://scikit-learn.org/stable/modules/svm.html"> [ svm.html ] </a> </li>
<li> Sensor Network Localization in Matlab: <a href="http://www.math.nus.edu.sg/~mattohkc/SNLSDP.html"> [ SNLSDP ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>03/27/2017, Mon </td>
<td>Lecture 08: Tree methods: CART, Bagging, Random Forests, and Boosting <a href="Lecture08_Ch8slide.pdf">[ slides ]</a> <a href="https://github.com/tpn/pdfs/blob/master/An%20Introduction%20To%20Statistical%20Learning%20with%20Applications%20in%20R%20(ISLR%20Sixth%20Printing).pdf">[ ISLR: Chap 8 ]</a> <br>
<ul>[Reference]: 
<li> Python Notebook: <a href="https://github.com/JWarmenhoven/ISLR-python/blob/master/Notebooks/Chapter%208.ipynb"> [ Chapter08.ipynb ] </a> </li>
<li> R code for lab: <a href="http://www-bcf.usc.edu/~gareth/ISL/Chapter%208%20Lab.txt"> [ Chapter08Lab.txt ] </a> </li>
<li> Mini-project 2 <a href="project2.pdf"> [ project2.pdf ] </a> </li>
<li> Kaggle in-class contest: <a href="https://inclass.kaggle.com/c/combodrug20">[ Combinatorial Drug 20 Efficacy ] </a> </li>
<li> Kaggle in-class contest: <a href="https://inclass.kaggle.com/c/drugsensitivity-2">[ OneDrug Sensitivity ]</a> </ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>04/03/2017, Mon </td>
<td>Lecture 09: Manifold Learning: ISOMAP, LLE and extended LLEs <a href="lecture09.1.pdf">[ lecture09.1.pdf ]</a> <a href="lecture09.2.pdf"> [ lecture09.2.pdf ]</a> <br>
<ul>[Reference]: 
<li> Python scikit-learn Manifold Learning: <a href="http://scikit-learn.org/stable/modules/manifold.html"> [ scikit-learn.manifold ] </a> </li>
<li> Todd Wittman's Matlab manifold learning comparison: <a href="http://math.stanford.edu/~yuany/course/data/mani.m"> [ mani.m ] </a> </li>
<li> Hau-Tieng Wu's Matlab codes on Vector Diffusion Map: <a href="https://sites.google.com/site/hautiengwu/home/download"> [ VDM ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>04/10/2017, Mon </td>
<td>Lecture 10: Topological Data Analysis <a href="lecture10.TDA.pdf">[ lecture10.pdf ] </a> <br>
<ul>[Reference]: 
<li> Project reports are at <a href="https://github.com/yuany-pku/2017_math6380"> [GitHub Math6380 web] </a> </li>
<li> In particular, all reports with source codes are placed at folder <a href="https://github.com/yuany-pku/2017_math6380/tree/master/project2"> [ Project2 reports ]</a> for peer review. </li>
<li> Submit your top 5 favorite reports (id and authors) on or before April 25, 2017, to datascience.hw email address. <i> No Self-vote! </i> That won't be counted. </li>
<li> Crowdsourced World College Ranking at allourideas: <a href="http://allourideas.org/worldcollege"> [ allourideas.org/worldcollege ] </a> </li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>04/17/2017, Mon </td>
<td>  Spring break<br>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td>04/24/2017, Mon </td>
<td>Lecture 11: Applied Hodge Theory: Social Choice and Game Theory etc. <a href="lecture11.Hodge.pdf">[ lecture11.pdf ] </a><br>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

<tr>
<td><a style="color:#FF0000 ">04/28/2017, Fri, 3-6pm, Room 2405 (lift 17-18) </a> </td>
<td>Lecture 12: An Odyssey on Representation Learning: A Brief Introduction to Neural Network <a href="lecture12.pdf"> [ lecture12.pdf ] </a> and <a href="project3.pdf">[ Final Project Description ]</a> <br>
<ul>[Reference]: 
<li> Notice: Room changed to 2405 (lift 17-18), 3-6pm!! </li> 
<li> Tutorial on MLP in R by JIANG, Yue <a href="Yue.MLP_in_R.pdf"> [ slides ]</a></li>
<li> Tutorial on Tensorflow by MIAO, Lizhang <a href="Tensorflow_tu.ipynb"> [ Tensorflow_tu.ipynb ] </a> viewed by <a href="https://nbviewer.jupyter.org/url/math.stanford.edu/~yuany/course/2017.spring/Tensorflow_tu.ipynb">[ Jupyter NBViewer ]</a></li>
<li> Tutorial on Reinforcement Learning by Akhan Ismailov <a href="Akhan.ReinforcementLearning.pptx"> [ slides ] </a> </li>
<li> After the deadline May 21, 2017, project reports will be collected at <a href="https://github.com/yuany-pku/2017_math6380"> [GitHub Math6380 web] </a> </li>
<li> Doodle Peer Review will be announced at <a href=""> [to-be-announced]</a></li>
</ul>
</td>
<td>Y.Y.</td>
<td></td>
</tr>

</tbody>
</table>

<br>

<h3><a name="data">Datasets (to-be-updated)</a></h3>

<ul>
<br>
<li> [Animal Sleep Data] <a href="http://math.stanford.edu/~yuany/course/data/sleep1.csv"> Animal species sleeping hours vs. other features </a>
</li>
<br>
<li> [Anzhen Heart Data] <a href="http://math.stanford.edu/~yuany/course/data/heartData_20140401.xlsx"> Heart Operation Effect Prediction</a>, provided by Dr. Jinwen Wang, Anzhen Hospital
</li>
<br>
<li> [Beer Data] <a href="http://math.stanford.edu/~yuany/course/data/Beers_20140514.xlsx"> 877 beers dataset </a>, provided by Mr. Richard Sun, Shanghai
</li>
<br>
<li> [Crime Data] <a href="http://math.stanford.edu/~yuany/course/data/crime.zip"> Crime rates in 59 US cities during 1970-1992 </a>
</li>
<br>
<li> [Real-Time-Bidding Algorithm Competition Data] <a href="http://contest.ipinyou.com/"> Contest Website </a>
</li>
<br>
<li> <a name="hongloumeng">[&#32418;&#27004;&#26790;&#20154;&#29289;&#20107;&#20214;&#30697;&#38453;]</a> a 376-by-475 matrix (374-by-475 updated by WAN, Mengting) for character-event appearance in A Dream of Red Mansion (Xueqin Cao) <a href="http://math.stanford.edu/~yuany/course/data/dream.RData"> [374 Characters dream.RData (for R load)] </a><a href="http://math.stanford.edu/~yuany/course/data/dream.Rd"> [dream.Rd (for R manual)] </a>  <a href="http://math.stanford.edu/~yuany/course/data/HongLouMeng374.txt"> [HongLouMeng374.txt] </a>  <a href="http://math.stanford.edu/~yuany/course/data/HongLouMeng376.csv"> [HongLouMeng376.csv] </a> <a href="http://math.stanford.edu/~yuany/course/data/hongloumeng376.mat"> [.mat] </a>
<a href="http://math.stanford.edu/~yuany/course/data/readme.m"> [readme.m] </a>
</li>
<br>
<li> <a name="data_xiyouji">[&#35199;&#28216;&#35760;]</a> characters-scene occurance matrices for 100 chapters <a href="http://math.stanford.edu/~yuany/course/data/west.RData">[data in RData]</a> <a href="http://math.stanford.edu/~yuany/course/data/xiyouji.mat"> [data in matlab (302-by-408 matrix)] </a>
<br>
<table border="1" cellspacing="0">
<tbody>
<tr>
<td align="left"><strong><a href="http://math.stanford.edu/~yuany/course/data/xiyouji/chap001-005.xls">chap001-005</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap006-009.xls">chap006-009</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap010-013.xls">chap010-013</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap014-017.xls">chap014-017</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap018-021.xls">chap018-021</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap022-025.xls">chap022-025</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap026-029.xls">chap026-029</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap030-033.xls">chap030-033</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap034-037.xls">chap034-037</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap038-041.xls">chap038-041</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap042-045.xls">chap042-045</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap046-049.xls">chap046-049</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap050-053.xls">chap050-053</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap054-057.xls">chap054-057</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap058-061.xls">chap058-061</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap062-065.xls">chap062-065</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap066-069.xls">chap066-069</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap070-073.xls">chap070-073</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap074-077.xls">chap074-077</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap078-081.xls">chap078-081</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap082-085.xls">chap082-085</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap086-088.xls">chap086-088</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap089-091.xls">chap089-091</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap092-094.xls">chap092-094</a></strong></td>
</tr>
<tr>
<td align="left"><strong><a href="../data/xiyouji/chap095-097.xls">chap095-097</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap098-100.xls">chap098-100</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/chap001-100_txt.zip">All in TXT</a></strong></td>
<td align="left"><strong><a href="../data/xiyouji/readData.m">readData.m</a></strong></td>
</tr>
</tbody>
</table>
</li>
<br>
<li> <a name="keywords">[Keywords Pricing]</a> Keywords and profit index in paid search advertising, by Hansheng Wang (Guanghua, PKU). <a href="http://math.stanford.edu/~yuany/course/2010.spring/Keyword/SE_slice.jpg"> [sample file] </a> <a href="http://math.stanford.edu/~yuany/course/2010.spring/Keyword/readme.txt"> [readme.txt] </a>  <a href="http://math.stanford.edu/~yuany/course/2010.spring/Keyword/SE.csv"> [data in csv] </a>
</li>
<br>
<li> [Radon Data] <a href="http://math.stanford.edu/~yuany/course/data/radon.csv"> Radon measurements of 12,687 houses in US </a>
</li>
<br>
<li> [Wells Data] <a href="http://math.stanford.edu/~yuany/course/data/wells.csv"> Switch unsafe wells for arsenic pollution in Bangladesh </a>
</li>
<br>
<li> to-be-done...
</li>
</ul>

<hr>

<address>
by <a href="http://www.math.pku.edu.cn/teachers/yaoy">YAO, Yuan</a>.
</address>

</body>
</html>
